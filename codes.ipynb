{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing required libraries, we will go on importing in our notebook code as we require\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from numpy import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function\n",
    "\n",
    "def lstm_lag(n):\n",
    "    \n",
    "    # reading data\n",
    "    data = pd.read_csv('converted.csv')\n",
    "    # shifting by specified lag\n",
    "    data['Inflation (Can)'] = data['Inflation (Can)'].shift(-1*n)\n",
    "    # other cleaning\n",
    "    data = data.head(84*30)\n",
    "    data.drop(['Period'],axis=1,inplace=True)\n",
    "\n",
    "    # scaling the data\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    y = scaled_data[:,0]\n",
    "    x = scaled_data[:,1:]\n",
    "    \n",
    "    # applying PCA to reduce number of features\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=5)\n",
    "    scaled_data = pca.fit_transform(x)\n",
    "\n",
    "    # splitting data into train and test sets\n",
    "    train_X = scaled_data[:72*30]\n",
    "    train_y = y[:72*30]\n",
    "    test_X = scaled_data[72*30:84*30]\n",
    "    test_y = y[72*30:84*30]\n",
    "\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "    # training lstm with a network and other parameters\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128,activation='relu', input_shape=(train_X.shape[1], train_X.shape[2]),return_sequences=True))\n",
    "    model.add(LSTM(128,return_sequences=True))\n",
    "    model.add(LSTM(64,return_sequences=True))\n",
    "    model.add(LSTM(16,return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    history = model.fit(train_X, train_y, epochs=10, batch_size=30, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "    \n",
    "    # plotting prediction results\n",
    "    yhat = model.predict(test_X)\n",
    "    # invert pca for forecast\n",
    "    test_X1 = pca.inverse_transform(test_X.reshape((test_X.shape[0], test_X.shape[2])))\n",
    "    # invert scaling for forecast\n",
    "    inv_yhat = concatenate((yhat.reshape(12*30,1), test_X1), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    a = inv_yhat\n",
    "    # invert scaling for actual\n",
    "    test_y1 = test_y.reshape((len(test_y), 1))\n",
    "    inv_y = concatenate((test_y1, test_X1), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:,0]\n",
    "    b = inv_y\n",
    "\n",
    "    pyplot.plot(inv_yhat, label='predicted')\n",
    "    pyplot.plot(inv_y, label='actual')\n",
    "    pyplot.legend()\n",
    "    pyplot.title(str(n)+'days lag')\n",
    "    pyplot.savefig('lstm'+str(n)+'.png')\n",
    "    pyplot.show()\n",
    "    \n",
    "    # printing mse and mae\n",
    "    print('mse = ',mean_squared_error(a,b))\n",
    "    print('mae = ',mean_absolute_error(a,b))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the number in argument from 0, 30, 60, 90 representing lag in number of days\n",
    "lstm_lag(90)\n",
    "\n",
    "# by running this cell, lstm model will be trained on data with specified lag\n",
    "# it will give output the mse and mae\n",
    "# it will show the graph of predictions and save that graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar function for svm\n",
    "\n",
    "def svm_lag(n):\n",
    "    data = pd.read_csv('raw_data.csv')\n",
    "    data['Inflation (Can)'] = data['Inflation (Can)'].shift(-1*n)\n",
    "    data = data.head(84)\n",
    "    data.drop(['Period'],axis=1,inplace=True)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    y = scaled_data[:,0]\n",
    "    x = scaled_data[:,1:]\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=5)\n",
    "    scaled_data = pca.fit_transform(x)\n",
    "\n",
    "    train_X = scaled_data[:72]\n",
    "    train_y = y[:72]\n",
    "    test_X = scaled_data[72:84]\n",
    "    test_y = y[72:84]\n",
    "\n",
    "    para = {\n",
    "    'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'tol' : [0.0001,0.0005,0.001,0.01,0.1],\n",
    "    'C' : [0.1,0.5,1,2]\n",
    "    }\n",
    "    grid_ser = GridSearchCV(SVR(),scoring = 'neg_mean_squared_error',param_grid=para ,n_jobs =1,cv = 4,verbose=0)\n",
    "    grid_ser.fit(train_X,train_y)\n",
    "\n",
    "    a = scaler.inverse_transform(\n",
    "    concatenate(\n",
    "    (grid_ser.best_estimator_.predict(test_X).reshape(12,-1),pca.inverse_transform(test_X)),\n",
    "     axis=1\n",
    "    )\n",
    "    )[:,0]\n",
    "\n",
    "    b = scaler.inverse_transform(\n",
    "    concatenate(\n",
    "    (test_y.reshape(12,-1),pca.inverse_transform(test_X)),\n",
    "     axis=1\n",
    "    )\n",
    "    )[:,0]\n",
    "\n",
    "    pyplot.plot(a, label='predicted')\n",
    "    pyplot.plot(b, label='actual')\n",
    "    pyplot.legend()\n",
    "    pyplot.savefig('svm'+str(n)+'.png')\n",
    "    pyplot.show()\n",
    "    \n",
    "    print('mse = ',mean_squared_error(a,b))\n",
    "    print('mae = ',mean_absolute_error(a,b))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the number in argument from 0, 1, 2, 3 representing lag in number of months\n",
    "\n",
    "svm_lag(3)\n",
    "\n",
    "# a similar function as of lstm with same attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
